{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_NLP_Project_version5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianp0513/NLP-project/blob/main/LSTM_NLP_Project_version5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNSxJX43nMhT"
      },
      "source": [
        "# model 1: two bidirectional LSTM\n",
        "# model 2: one bidirectional LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXmofp6Qkh1o",
        "outputId": "12bfcd6f-6168-44be-e638-9e6f6b12a797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHifi-2u9F7P",
        "outputId": "6815924b-20c2-4a19-dcca-ea184edddf82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "# import seaborn as sns\n",
        "import time\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import random\n",
        "import os\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sGqNLtcllWd"
      },
      "source": [
        "def getTextFromFiles(df, data_path, depression, limit):\n",
        "    \"\"\"Return Data Frame \"\"\"\n",
        "\n",
        "    for file in os.listdir(data_path)[:limit]:\n",
        "        with open(data_path + \"/\" + file, 'r', encoding=\"ISO-8859-1\") as file1:\n",
        "            file1 = file1.read()\n",
        "            df = df.append({'text': file1, 'depression': int(depression)}, ignore_index=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-vwDEhlmvg"
      },
      "source": [
        "data_path_d = \"/content/drive/My Drive/NLP Team/code/kerasData/reddit_depression\"\n",
        "data_path_nd = \"/content/drive/My Drive/NLP Team/code/kerasData/reddit_non_depression\"\n",
        "df = pd.DataFrame(columns=['text', 'depression'])\n",
        "df = getTextFromFiles(df, data_path_d, 1, 500)\n",
        "df = getTextFromFiles(df, data_path_nd, 0, 500)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLgl-2iYDNp7"
      },
      "source": [
        "X = df['text'].to_numpy()\n",
        "Y = df['depression'].to_numpy()\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n",
        "# max_words = 1000\n",
        "max_words = 1000\n",
        "max_len = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "# sequences_matrix = tokenizer.sequences_to_matrix(sequences, mode='binary')\n",
        "# sequences_matrix = tokenizer.sequences_to_matrix(sequences, mode='count')\n",
        "# sequences_matrix = tokenizer.sequences_to_matrix(sequences, mode='freq')\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# test_sequences_matrix = tokenizer.sequences_to_matrix(test_sequences, mode='binary')\n",
        "# test_sequences_matrix = tokenizer.sequences_to_matrix(test_sequences, mode='count')\n",
        "# test_sequences_matrix = tokenizer.sequences_to_matrix(test_sequences, mode='freq')\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoWITqLjhRLD"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAAU74hebDPt"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(np.array(sequences).shape)\n",
        "# print(np.array(sequences))\n",
        "print(sequences_matrix.shape)\n",
        "# print(Y_train.shape)\n",
        "# print(tok.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lug--zRbEO9C"
      },
      "source": [
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim = max_words, output_dim = 8, input_length= max_len))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64 , return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(80))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "model.build(input_shape=sequences_matrix.shape)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9SKloVwm8Fq"
      },
      "source": [
        "\n",
        "model.fit(sequences_matrix, Y_train.astype(float), batch_size=4,epochs=40,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
        "accr = model.evaluate(test_sequences_matrix,Y_test.astype(float))\n",
        "print(\"1 bidirectional LSTM\")\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQEtBmFNUWHI"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim = max_words, output_dim = 10, input_length= max_len))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Dense(80))\n",
        "model.add(tf.keras.layers.Activation('tanh'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "model.build(input_shape=sequences_matrix.shape)\n",
        "# opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "# model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
        "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2RpwX2EiHj",
        "outputId": "e23ec108-bc7d-4576-dae9-d26a914034d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(sequences_matrix, Y_train.astype(float), batch_size=4,epochs=40,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
        "accr = model.evaluate(test_sequences_matrix,Y_test.astype(float))\n",
        "print(\"1 bidirectional LSTM\")\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "170/170 [==============================] - 4s 25ms/step - loss: 0.6885 - accuracy: 0.5701 - val_loss: 0.6732 - val_accuracy: 0.5915\n",
            "Epoch 2/40\n",
            "170/170 [==============================] - 4s 21ms/step - loss: 0.6607 - accuracy: 0.6102 - val_loss: 0.6261 - val_accuracy: 0.6639\n",
            "Epoch 3/40\n",
            "170/170 [==============================] - 4s 21ms/step - loss: 0.5543 - accuracy: 0.7405 - val_loss: 0.4837 - val_accuracy: 0.8342\n",
            "Epoch 4/40\n",
            "170/170 [==============================] - 4s 22ms/step - loss: 0.4004 - accuracy: 0.8590 - val_loss: 0.4515 - val_accuracy: 0.8533\n",
            "Epoch 5/40\n",
            "170/170 [==============================] - 3s 20ms/step - loss: 0.3360 - accuracy: 0.8826 - val_loss: 0.4424 - val_accuracy: 0.8644\n",
            "Epoch 6/40\n",
            "170/170 [==============================] - 4s 21ms/step - loss: 0.3121 - accuracy: 0.8928 - val_loss: 0.4228 - val_accuracy: 0.8584\n",
            "Epoch 7/40\n",
            "170/170 [==============================] - 4s 21ms/step - loss: 0.2592 - accuracy: 0.9197 - val_loss: 0.4341 - val_accuracy: 0.8632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f05f727d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2a6CmieEzbM",
        "outputId": "56230c2d-5528-4813-8ffb-4384b562fcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4467 - accuracy: 0.8472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fAtJZ3mEzUO",
        "outputId": "8b63240e-3795-45b8-a25c-cd1c6b14f6ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set\n",
            "  Loss: 0.447\n",
            "  Accuracy: 0.847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFsymIRQmwv"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}